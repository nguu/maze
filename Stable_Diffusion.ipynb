{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOCwPEEpafyC"
      },
      "source": [
        "# Stable Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enviroments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sRfqjpCScB-5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "\n",
        "USE_DRIVE = False #@param {type:'boolean'}\n",
        "DRIVE_DIR = '/content/drive' #@param {type:'string'}\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount(DRIVE_DIR)\n",
        "\n",
        "%pip install -q torch diffusers accelerate transformers compel\n",
        "%pip install -q omegaconf ipywidgets controlnet-aux mediapipe\n",
        "\n",
        "def save_image(img, dir: str, tmp: str = '') -> str:\n",
        "  if not os.path.exists(dir):\n",
        "    os.makedirs(dir)\n",
        "  img_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "  img_name = f'{img_time}-{tmp}' if tmp != '' else img_time\n",
        "  img_path = os.path.join(dir, f'{img_name}.png')\n",
        "  img.save(img_path)\n",
        "  return img_path\n",
        "\n",
        "\n",
        "def get_model_list(dir: str) -> dict:\n",
        "  items = {}\n",
        "  allowed_extensions = {'.ckpt' , '.pt', '.pth', '.safetensors', '.bin'}\n",
        "  for file in os.listdir(dir):\n",
        "    if os.path.splitext(file)[1] in allowed_extensions:\n",
        "      file_name = os.path.splitext(file)[0]\n",
        "      file_path = os.path.join(dir, file)\n",
        "      items[file_name] = file_path\n",
        "  return items\n",
        "\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "def resize_and_crop_image(image, target_width=576, target_height=1024):\n",
        "    original_width, original_height = image.size\n",
        "    aspect_ratio = original_width / original_height\n",
        "\n",
        "    target_aspect_ratio = target_width / target_height\n",
        "    if aspect_ratio > target_aspect_ratio:\n",
        "        # Image is wider than target, resize based on width\n",
        "        new_width = target_width\n",
        "        new_height = int(new_width / aspect_ratio)\n",
        "    else:\n",
        "        # Image is taller than target, resize based on height\n",
        "        new_height = target_height\n",
        "        new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "    resized_image = image.resize((new_width, new_height))\n",
        "    # Calculate cropping offset to center the image within the target dimensions\n",
        "    offset_x = math.floor((new_width - target_width) / 2)\n",
        "    offset_y = math.floor((new_height - target_height) / 2)\n",
        "\n",
        "    cropped_image = resized_image.crop((offset_x, offset_y, offset_x + target_width, offset_y + target_height))\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "def batch_resize_and_crop(images, target_width = 576, target_height = 1024):\n",
        "    return [\n",
        "        resize_and_crop_image(image, target_width, target_height)\n",
        "        for image in images\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "prhlqdFPcA4k"
      },
      "outputs": [],
      "source": [
        "#@title Define classes, methods\n",
        "import os\n",
        "import torch\n",
        "from compel import Compel\n",
        "from diffusers import (\n",
        "    AutoencoderKL,\n",
        "    ControlNetModel,\n",
        "    StableDiffusionPipeline,\n",
        "    StableDiffusionImg2ImgPipeline,\n",
        "    StableDiffusionInpaintPipeline,\n",
        "    StableDiffusionControlNetPipeline,\n",
        "    StableDiffusionControlNetImg2ImgPipeline,\n",
        "    StableDiffusionControlNetInpaintPipeline,\n",
        "    DPMSolverMultistepScheduler,\n",
        "    DPMSolverSinglestepScheduler,\n",
        "    KDPM2DiscreteScheduler,\n",
        "    KDPM2AncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    HeunDiscreteScheduler,\n",
        ")\n",
        "from diffusers.pipelines.controlnet import MultiControlNetModel\n",
        "from controlnet_aux.processor import Processor\n",
        "\n",
        "CONTROLNET_REPOS = {\n",
        "  'canny': 'lllyasviel/control_v11p_sd15_canny',\n",
        "  'depth': 'lllyasviel/control_v11f1p_sd15_depth',\n",
        "  'inpaint': 'lllyasviel/control_v11p_sd15_inpaint',\n",
        "  'ip2p': 'lllyasviel/control_v11e_sd15_ip2p',\n",
        "  'lineart': 'lllyasviel/control_v11p_sd15_lineart',\n",
        "  'lineart_anime': 'lllyasviel/control_v11p_sd15s2_lineart_anime',\n",
        "  'mlsd': 'lllyasviel/control_v11p_sd15_mlsd',\n",
        "  'normalbae': 'lllyasviel/control_v11p_sd15_normalbae',\n",
        "  'openpose': 'lllyasviel/control_v11p_sd15_openpose',\n",
        "  'scribble': 'lllyasviel/control_v11p_sd15_scribble',\n",
        "  'segmentation': 'lllyasviel/control_v11p_sd15_seg',\n",
        "  'shuffle': 'lllyasviel/control_v11e_sd15_shuffle',\n",
        "  'softedge': 'lllyasviel/control_v11p_sd15_softedge',\n",
        "}\n",
        "\n",
        "AUX_PROCESSOR = [\n",
        "    \"canny\",\n",
        "    \"depth_leres\",\n",
        "    \"depth_leres++\",\n",
        "    \"depth_midas\",\n",
        "    \"depth_zoe\",\n",
        "    \"lineart_anime\",\n",
        "    \"lineart_coarse\",\n",
        "    \"lineart_realistic\",\n",
        "    \"mediapipe_face\",\n",
        "    \"mlsd\",\n",
        "    \"normal_bae\",\n",
        "    \"normal_midas\",\n",
        "    \"openpose\",\n",
        "    \"openpose_face\",\n",
        "    \"openpose_faceonly\",\n",
        "    \"openpose_full\",\n",
        "    \"openpose_hand\",\n",
        "    \"scribble_hed\",\n",
        "    \"scribble_pidinet\",\n",
        "    \"shuffle\",\n",
        "    \"softedge_hed\",\n",
        "    \"softedge_hedsafe\",\n",
        "    \"softedge_pidinet\",\n",
        "    \"softedge_pidsafe\",\n",
        "    \"dwpose\",\n",
        "]\n",
        "\n",
        "\n",
        "class AnnotatorService:\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "\n",
        "    def process(self, images: dict):\n",
        "        result = []\n",
        "\n",
        "        if list(self.models.keys()) != list(images.keys()):\n",
        "            self.models = {}\n",
        "            for name in images.keys():\n",
        "                self.models[name] = None if name == 'none' else Processor(name)\n",
        "\n",
        "        for name, image in images.items():\n",
        "            new_image = Image.open(image)\n",
        "            if name == 'none':\n",
        "                result.append(new_image)\n",
        "                continue\n",
        "            new_image = self.models[name](new_image, to_pil=True)\n",
        "            result.append(new_image)\n",
        "        return result\n",
        "\n",
        "\n",
        "class StableDiffusionService:\n",
        "    def __init__(self):\n",
        "        self.task = ''\n",
        "        self.pipe = None\n",
        "        self.compel = None\n",
        "        self.ldm = ''\n",
        "        self.vae = ''\n",
        "        self.controlnets = []\n",
        "        self.cfg = {'torch_dtype': torch.float16}\n",
        "    \n",
        "\n",
        "    def load_ldm(self, ldm: str):\n",
        "        if self.pipe and self.ldm == ldm:\n",
        "            print('LDM: from cache')\n",
        "            return\n",
        "\n",
        "        cfg = {'torch_dtype': torch.float16, 'token': False}\n",
        "\n",
        "        if not os.path.isfile(ldm):\n",
        "            self.pipe = StableDiffusionPipeline.from_pretrained(ldm, **cfg)\n",
        "        else:\n",
        "            self.pipe = StableDiffusionPipeline.from_single_file(ldm, **cfg)\n",
        "\n",
        "        self.compel = Compel(self.pipe.tokenizer, self.pipe.text_encoder)\n",
        "        self.pipe.safety_checker = None\n",
        "        self.pipe.to('cuda')\n",
        "        self.ldm = ldm\n",
        "        self.task = 'txt2img'\n",
        "\n",
        "\n",
        "    def load_vae(self, vae: str):\n",
        "        if not self.vae and vae == 'none':\n",
        "            return\n",
        "\n",
        "        if self.vae == vae:\n",
        "            print('VAE: from cache')\n",
        "            return\n",
        "\n",
        "        if self.pipe.vae and vae == 'none':\n",
        "            del self.pipe.vae\n",
        "            print('VAE: set None')\n",
        "            return\n",
        "        elif os.path.isfile(vae):\n",
        "            self.pipe.vae = AutoencoderKL.from_single_file(vae, **self.cfg)\n",
        "        else:\n",
        "            self.pipe.vae = AutoencoderKL.from_pretrained(vae, **self.cfg)\n",
        "\n",
        "        self.vae = vae\n",
        "        self.pipe.vae.to('cuda')\n",
        "\n",
        "\n",
        "    def load_controlnet(self, task: str, controlnets: list):\n",
        "        if self.task == task and self.controlnets == controlnets:\n",
        "            return\n",
        "\n",
        "        components = self.pipe.components\n",
        "\n",
        "        if self.controlnets != controlnets:\n",
        "            models = [\n",
        "                ControlNetModel.from_pretrained(name, torch_dtype=torch.float16)\n",
        "                for name in controlnets\n",
        "            ]\n",
        "            components['controlnet'] = MultiControlNetModel(models)\n",
        "            print(f'Controlnets: {\",\".join(controlnets)} have been loaded')\n",
        "\n",
        "            if not controlnets:\n",
        "                components.pop('controlnet')\n",
        "\n",
        "        if 'controlnet' in components:\n",
        "            if task == 'txt2img':\n",
        "                self.pipe = StableDiffusionControlNetPipeline(**components)\n",
        "            if task == 'img2img':\n",
        "                self.pipe = StableDiffusionControlNetImg2ImgPipeline(**components)\n",
        "            if task == 'inpaint':\n",
        "                self.pipe = StableDiffusionControlNetInpaintPipeline(**components)\n",
        "        else:\n",
        "            if task == 'txt2img':\n",
        "                self.pipe = StableDiffusionPipeline(**components)\n",
        "            if task == 'img2img':\n",
        "                self.pipe = StableDiffusionImg2ImgPipeline(**components)\n",
        "            if task == 'inpaint':\n",
        "                self.pipe = StableDiffusionInpaintPipeline(**components)\n",
        "\n",
        "        self.task = task\n",
        "        self.controlnets = controlnets\n",
        "\n",
        "\n",
        "    def set_scheduler(self, name: str):\n",
        "        match name:\n",
        "            case \"DPM++ 2M\":\n",
        "                sampler = DPMSolverMultistepScheduler.from_config(self.pipe.scheduler.config)\n",
        "            case \"DPM++ 2M Karras\":\n",
        "                sampler = DPMSolverMultistepScheduler.from_config(self.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "            case \"DPM++ 2M SDE\":\n",
        "                sampler = DPMSolverMultistepScheduler.from_config(self.pipe.scheduler.config, algorithm_type=\"sde-dpmsolver++\")\n",
        "            case \"DPM++ 2M SDE Karras\":\n",
        "                sampler = DPMSolverMultistepScheduler.from_config(self.pipe.scheduler.config, use_karras_sigmas=True, algorithm_type=\"sde-dpmsolver++\")\n",
        "            case \"DPM++ SDE\":\n",
        "                sampler = DPMSolverSinglestepScheduler.from_config(self.pipe.scheduler.config)\n",
        "            case \"DPM++ SDE Karras\":\n",
        "                sampler = DPMSolverSinglestepScheduler.from_config(self.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "            case \"DPM2\":\n",
        "                sampler = KDPM2DiscreteScheduler.from_config(self.pipe.scheduler.config)\n",
        "            case \"DPM2 Karras\":\n",
        "                sampler = KDPM2DiscreteScheduler.from_config(self.pipe.scheduler.config, use_karras_sigmas=True)\n",
        "            case \"Euler\":\n",
        "                sampler = EulerDiscreteScheduler.from_config(self.pipe.scheduler.config)\n",
        "            case \"Euler a\":\n",
        "                sampler = EulerAncestralDiscreteScheduler.from_config(self.pipe.scheduler.config)\n",
        "            case \"Heun\":\n",
        "                sampler = HeunDiscreteScheduler.from_config(self.pipe.scheduler.config)\n",
        "            case _:\n",
        "                sampler = EulerAncestralDiscreteScheduler.from_config(self.pipe.scheduler.config)\n",
        "        self.pipe.scheduler = sampler\n",
        "\n",
        "    def __call__(self, **kwargs):\n",
        "        return self.pipe(**kwargs).images\n",
        "\n",
        "\n",
        "app = StableDiffusionService()\n",
        "annotator = AnnotatorService()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "f8Ze8GkV_Le4"
      },
      "outputs": [],
      "source": [
        "#@title Define user interface\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display\n",
        "\n",
        "class ControlnetUserInterface:\n",
        "    def __init__(\n",
        "        self,\n",
        "        title: str,\n",
        "        preprocessor: list = AUX_PROCESSOR,\n",
        "        processor: list = list(CONTROLNET_REPOS.keys())\n",
        "    ):\n",
        "        self.title = title\n",
        "        self.element_layout = widgets.Layout(width='initial')\n",
        "        self.enabled = widgets.Checkbox(\n",
        "            description='Enabled',\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.preprocessor = widgets.Dropdown(\n",
        "            description='Preprocessor',\n",
        "            options=['none'] + preprocessor,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.processor = widgets.Dropdown(\n",
        "            description='Model',\n",
        "            options=['none'] + processor,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.image = widgets.Text(\n",
        "            description='Image',\n",
        "            placeholder='/content/image.jpg',\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.weight = widgets.FloatSlider(\n",
        "            description='Weight',\n",
        "            value=1.0,\n",
        "            min=0.0,\n",
        "            max=1.0,\n",
        "            step=0.1,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.start = widgets.FloatSlider(\n",
        "            description='Start Threshold',\n",
        "            value=0.0,\n",
        "            min=0.0,\n",
        "            max=1.0,\n",
        "            step=0.1,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.end = widgets.FloatSlider(\n",
        "            description='Stop Threshold',\n",
        "            value=1.0,\n",
        "            min=0.0,\n",
        "            max=1.0,\n",
        "            step=0.1,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "\n",
        "    def widget(self):\n",
        "        return widgets.VBox([\n",
        "            widgets.Label(self.title),\n",
        "            self.enabled,\n",
        "            self.image,\n",
        "            self.preprocessor,\n",
        "            self.processor,\n",
        "            self.weight,\n",
        "            self.start,\n",
        "            self.end,\n",
        "        ])\n",
        "\n",
        "\n",
        "class StableDiffusionUserInterface:\n",
        "    def __init__(self, ldm_items: list, vae_items: list):\n",
        "        self.element_layout = widgets.Layout(width='initial')\n",
        "        self.ldm = widgets.Dropdown(\n",
        "            options=ldm_items,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.ldm_path = widgets.Text(\n",
        "            placeholder='runwayml/stable-diffusion-v1-5',\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.vae = widgets.Dropdown(\n",
        "            options=vae_items,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.vae_path = widgets.Text(\n",
        "            placeholder='stabilityai/sd-vae-ft-ema',\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.scheduler = widgets.Dropdown(\n",
        "            description='Scheduler',\n",
        "            options=[\n",
        "                'DPM++ 2M',\n",
        "                'DPM++ 2M Karras',\n",
        "                'DPM++ 2M SDE',\n",
        "                'DPM++ 2M SDE Karras',\n",
        "                'DPM++ SDE',\n",
        "                'DPM++ SDE Karras',\n",
        "                'DPM2',\n",
        "                'DPM2 Karras',\n",
        "                'Euler',\n",
        "                'Euler a',\n",
        "                'Heun',\n",
        "            ],\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.steps = widgets.IntText(\n",
        "            description='Steps',\n",
        "            value=30,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.cfg = widgets.FloatText(\n",
        "            description='CFG',\n",
        "            value=7.5,\n",
        "            step=0.1,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.width = widgets.IntText(\n",
        "            description='Width',\n",
        "            value=576,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.height = widgets.IntText(\n",
        "            description='Height',\n",
        "            value=1024,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.seed = widgets.IntText(\n",
        "            description='Seed',\n",
        "            value=-1,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.batch_size = widgets.IntText(\n",
        "            description='Batch Size',\n",
        "            value=1,\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.task = widgets.Dropdown(\n",
        "            description='Task',\n",
        "            options=['txt2img', 'img2img', 'inpaint'],\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.prompt = widgets.Textarea(\n",
        "            description='Prompt',\n",
        "            rows=5,\n",
        "            value='best quality, highly detailed',\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.negative_prompt = widgets.Textarea(\n",
        "            description='Negative Prompt',\n",
        "            rows=5,\n",
        "            value='low quality, watermark, logo, blurry, monochrome',\n",
        "            layout=self.element_layout,\n",
        "        )\n",
        "        self.input_image = widgets.Text(\n",
        "            description='Input Image',\n",
        "            placeholder='/content/example.jpg',\n",
        "            layout=widgets.Layout(width='initial', display='none'),\n",
        "        )\n",
        "        self.input_mask = widgets.Text(\n",
        "            description='Input Mask',\n",
        "            placeholder='/content/example.jpg',\n",
        "            layout=widgets.Layout(width='initial', display='none'),\n",
        "        )\n",
        "        self.denoising_strength = widgets.FloatSlider(\n",
        "            description='Denoising Strength',\n",
        "            value=0.75,\n",
        "            min=0.0,\n",
        "            max=1.0,\n",
        "            step=0.05,\n",
        "            layout=widgets.Layout(width='initial', display='none'),\n",
        "        )\n",
        "        self.generate_button = widgets.Button(\n",
        "            description='Generate',\n",
        "            button_style='primary',\n",
        "        )\n",
        "        self.clear_button = widgets.Button(\n",
        "            description='Clear Output',\n",
        "        )\n",
        "\n",
        "        self.controlnets = [\n",
        "            ControlnetUserInterface('Controlnet 1'),\n",
        "            ControlnetUserInterface('Controlnet 2'),\n",
        "            ControlnetUserInterface('Controlnet 3'),\n",
        "        ]\n",
        "        self.task.observe(self.on_task_change, names='value')\n",
        "\n",
        "    def on_task_change(self, change):\n",
        "        self.input_image.layout.display = 'none' if change['new'] == 'txt2img' else ''\n",
        "        self.denoising_strength.layout.display = 'none' if change['new'] == 'txt2img' else ''\n",
        "        self.input_mask.layout.display = 'none' if change['new'] != 'inpaint' else ''\n",
        "\n",
        "    def get_inputs(self) -> dict:\n",
        "        control_image = {}\n",
        "        control_processor = []\n",
        "        control_weight = []\n",
        "        control_start = []\n",
        "        control_end = []\n",
        "\n",
        "        for control in self.controlnets:\n",
        "            if control.enabled.value:\n",
        "                control_image[control.preprocessor.value] = control.image.value or self.input_image.value\n",
        "                control_processor.append(control.processor.value)\n",
        "                control_weight.append(control.weight.value)\n",
        "                control_start.append(control.start.value)\n",
        "                control_end.append(control.end.value)\n",
        "\n",
        "        return {\n",
        "            'task': self.task.value,\n",
        "            'ldm': self.ldm.value,\n",
        "            'ldm_path': self.ldm_path.value,\n",
        "            'vae': self.vae.value,\n",
        "            'vae_path': self.vae_path.value,\n",
        "            'prompt': self.prompt.value,\n",
        "            'negative_prompt': self.negative_prompt.value,\n",
        "            'guidance_scale': self.cfg.value,\n",
        "            'num_inference_steps': self.steps.value,\n",
        "            'num_images_per_prompt': self.batch_size.value,\n",
        "            'width': self.width.value,\n",
        "            'height': self.height.value,\n",
        "            'seed': self.seed.value,\n",
        "            'image': self.input_image.value,\n",
        "            'mask_image': self.input_mask.value,\n",
        "            'control_image': control_image,\n",
        "            'control_processor': control_processor,\n",
        "            'controlnet_conditioning_scale': control_weight,\n",
        "            'control_guidance_start': control_start,\n",
        "            'control_guidance_end': control_end,\n",
        "            'scheduler': self.scheduler.value,\n",
        "            'strength': self.denoising_strength.value,\n",
        "        }\n",
        "\n",
        "    def widget(self):\n",
        "        buttons = widgets.HBox(\n",
        "            [self.generate_button, self.clear_button],\n",
        "            layout=widgets.Layout(\n",
        "                width='100%',\n",
        "                display='flex',\n",
        "                justify_content='center',\n",
        "            )\n",
        "        )\n",
        "\n",
        "        header = widgets.HBox([\n",
        "            widgets.VBox([\n",
        "                widgets.Label('Checkpoint'),\n",
        "                self.ldm,\n",
        "                self.ldm_path,\n",
        "            ], layout=widgets.Layout(width='inherit')),\n",
        "            widgets.VBox([\n",
        "                widgets.Label('VAE'),\n",
        "                self.vae,\n",
        "                self.vae_path,\n",
        "            ], layout=widgets.Layout(width='inherit')),\n",
        "        ], layout=widgets.Layout(width='100%', margin='0px 0px 16px 0px')\n",
        "        )\n",
        "\n",
        "        body = widgets.GridspecLayout(2, 3, grid_gap='8px')\n",
        "        body[0, 0] = widgets.VBox([\n",
        "            self.scheduler,\n",
        "            self.steps,\n",
        "            self.cfg,\n",
        "            self.width,\n",
        "            self.height,\n",
        "            self.seed,\n",
        "            self.batch_size,\n",
        "        ], layout=widgets.Layout(width='100%'))\n",
        "\n",
        "        body[0, 1:] = widgets.VBox([\n",
        "            self.task,\n",
        "            self.input_image,\n",
        "            self.input_mask,\n",
        "            self.prompt,\n",
        "            self.negative_prompt,\n",
        "            self.denoising_strength,\n",
        "            buttons,\n",
        "        ])\n",
        "\n",
        "        body[1, 0] = self.controlnets[0].widget()\n",
        "        body[1, 1] = self.controlnets[1].widget()\n",
        "        body[1, 2] = self.controlnets[2].widget()\n",
        "\n",
        "        layout = widgets.VBox([\n",
        "            header,\n",
        "            body,\n",
        "        ])\n",
        "\n",
        "        return layout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HYVudjfdQGPv"
      },
      "outputs": [],
      "source": [
        "#@title Download (Optional)\n",
        "from torch.hub import download_url_to_file\n",
        "\n",
        "DOWNLOAD_DIR = '/content/drive/MyDrive/sd/vae' #@param {type:'string'}\n",
        "DOWNLOAD_URL = 'https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors' #@param {type:'string'}\n",
        "DOWNLOAD_OUT = 'vae-ft-mse-840000-ema-pruned.safetensors' #@param {type:'string'}\n",
        "\n",
        "if not os.path.exists(DOWNLOAD_DIR):\n",
        "    os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "if DOWNLOAD_DIR and DOWNLOAD_URL and DOWNLOAD_OUT:\n",
        "    download_url_to_file(DOWNLOAD_URL, f'{DOWNLOAD_DIR}/{DOWNLOAD_OUT}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VNEg7Gg9_ezA"
      },
      "outputs": [],
      "source": [
        "# @title Generate { display-mode: \"form\" }\n",
        "import random\n",
        "\n",
        "OUT_DIR = '/content/out' #@param {type:'string'}\n",
        "LDM_DIR = '/content/drive/MyDrive/sd/ldm' #@param {type:'string'}\n",
        "VAE_DIR = '/content/drive/MyDrive/sd/vae' #@param {type:'string'}\n",
        "\n",
        "ldm_checkpoints = {}\n",
        "vae_checkpoints = {}\n",
        "\n",
        "if os.path.exists(LDM_DIR):\n",
        "    ldm_checkpoints = get_model_list(LDM_DIR)\n",
        "\n",
        "if os.path.exists(VAE_DIR):\n",
        "    vae_checkpoints = get_model_list(VAE_DIR)\n",
        "\n",
        "ui = StableDiffusionUserInterface(\n",
        "    list(ldm_checkpoints.keys()) or ['none'],\n",
        "    ['none'] + list(vae_checkpoints.keys()),\n",
        ")\n",
        "applog = widgets.Output()\n",
        "\n",
        "def on_click_generate_button(b):\n",
        "    applog.clear_output()\n",
        "    with applog:\n",
        "        inputs: dict = ui.get_inputs()\n",
        "        if not inputs['ldm'] and not inputs['ldm_path']:\n",
        "            print('require LDM checkpoint')\n",
        "            return\n",
        "\n",
        "        task = inputs.pop('task', 'txt2img')\n",
        "        seed = inputs.pop('seed', -1)\n",
        "        ldm = inputs.pop('ldm')\n",
        "        ldm_path = inputs.pop('ldm_path')\n",
        "        vae = inputs.pop('vae')\n",
        "        vae_path = inputs.pop('vae_path')\n",
        "        prompt = inputs.pop('prompt')\n",
        "        negative_prompt = inputs.pop('negative_prompt')\n",
        "        scheduler = inputs.pop('scheduler')\n",
        "        control_processor = inputs.pop('control_processor', [])\n",
        "        control_repos = [CONTROLNET_REPOS[name] for name in control_processor]\n",
        "\n",
        "        app.load_ldm(ldm_path or ldm_checkpoints[ldm])\n",
        "        app.load_vae(vae_path or vae_checkpoints.get(vae, 'none'))\n",
        "        app.load_controlnet(task, control_repos)\n",
        "        app.set_scheduler(scheduler)\n",
        "        app.pipe.to('cuda')\n",
        "\n",
        "        inputs['prompt_embeds'] = app.compel(prompt)\n",
        "        inputs['negative_prompt_embeds'] = app.compel(negative_prompt)\n",
        "\n",
        "        calculate_seed = random.randint(0, 999999999) if seed == -1 else seed\n",
        "        generator = torch.Generator(device=\"cuda\").manual_seed(calculate_seed)\n",
        "        inputs['generator'] = generator\n",
        "\n",
        "        if inputs['control_image']:\n",
        "            inputs['control_image'] = annotator.process(inputs['control_image'])\n",
        "            inputs['control_image'] = batch_resize_and_crop(\n",
        "                inputs['control_image'],\n",
        "                inputs['width'],\n",
        "                inputs['height'],\n",
        "            )\n",
        "\n",
        "        if task == 'txt2img' and control_processor:\n",
        "            inputs['image'] = inputs['control_image']\n",
        "\n",
        "        if task in ['img2img', 'inpaint']:\n",
        "            inputs['image'] = [Image.open(inputs['image']).convert('RGB')]\n",
        "\n",
        "        if task == 'inpaint':\n",
        "            mask_path = inputs['mask_image']\n",
        "            inputs['mask_image'] = [Image.open(mask_path).convert('RGB')]\n",
        "\n",
        "        images = []\n",
        "        images = app(**inputs)\n",
        "        if len(images) > 0:\n",
        "            print(f\"Prompt: {prompt}\")\n",
        "            print(f\"Negative Prompt: {negative_prompt}\")\n",
        "            print(f\"Seed: {calculate_seed}\")\n",
        "            for index, img in enumerate(images):\n",
        "                dir = OUT_DIR\n",
        "                img_path = save_image(img, dir, f'{calculate_seed}-{index}')\n",
        "                print(f'Saved: {img_path}')\n",
        "\n",
        "            if inputs['control_image']:\n",
        "                images = images + inputs['control_image']\n",
        "\n",
        "            total = len(images)\n",
        "            row = 1 if total % 4 != 0 else total // 4\n",
        "            col = total if row == 1 else 4\n",
        "            grid = image_grid(images, row, col)\n",
        "            display(grid)\n",
        "        else:\n",
        "            print('Empty!')\n",
        "\n",
        "def on_click_clear_button(b):\n",
        "    applog.clear_output()\n",
        "\n",
        "ui.generate_button._click_handlers.callbacks = []\n",
        "ui.generate_button.on_click(on_click_generate_button)\n",
        "ui.clear_button._click_handlers.callbacks = []\n",
        "ui.clear_button.on_click(on_click_clear_button)\n",
        "\n",
        "display(ui.widget())\n",
        "display(applog)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Controlnet Annotators {display-mode:\"form\"}\n",
        "\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display\n",
        "\n",
        "AUX_OUT_DIR = '/content/aux' #@param {type:'string'}\n",
        "os.makedirs(AUX_OUT_DIR, exist_ok=True)\n",
        "\n",
        "def aux_process(processor, input):\n",
        "    model = Processor(processor)\n",
        "    return model(input, to_pil=True)\n",
        "\n",
        "aux_log = widgets.Output()\n",
        "\n",
        "aux_input = widgets.Text(\n",
        "  description='Input',\n",
        "  placeholder='/content/input.jpg'\n",
        ")\n",
        "\n",
        "aux_processor = widgets.Dropdown(\n",
        "  description='Processor',\n",
        "  options=AUX_PROCESSOR,\n",
        ")\n",
        "\n",
        "aux_button = widgets.Button(\n",
        "  description='Process',\n",
        "  button_style='primary',\n",
        ")\n",
        "\n",
        "aux_layout = widgets.VBox([\n",
        "  aux_processor,\n",
        "  aux_input,\n",
        "  aux_button,\n",
        "])\n",
        "\n",
        "def aux_on_click(b):\n",
        "  aux_log.clear_output()\n",
        "  with aux_log:\n",
        "    if not os.path.exists(aux_input.value):\n",
        "      print(f'Input: {aux_input.value} not found')\n",
        "      return\n",
        "\n",
        "    input = Image.open(aux_input.value).convert('RGB')\n",
        "    result = aux_process(aux_processor.value, input)\n",
        "    output = f'{AUX_OUT_DIR}/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.png'\n",
        "    if result.save(output):\n",
        "      print(f'Saved: {output}')\n",
        "\n",
        "aux_button._click_handlers.callbacks = []\n",
        "aux_button.on_click(aux_on_click)\n",
        "display(aux_layout)\n",
        "display(aux_log)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
