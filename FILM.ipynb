{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrnrpJwVrLHQ"
      },
      "source": [
        "# FILM: Frame Interpolation for Large Motion\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nguu/maze/blob/main/FILM.ipynb)\n",
        "[![GitHub Repository](https://img.shields.io/github/stars/google-research/frame-interpolation?style=social)](https://github.com/google-research/frame-interpolation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MACAmsRIvC6e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import bisect\n",
        "import shutil\n",
        "\n",
        "FILM_DIR = f'/content/film'\n",
        "CKPT_DIR = f'{FILM_DIR}/pretrained'\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "%pip install -q tqdm\n",
        "\n",
        "def pad_batch(batch, align):\n",
        "    height, width = batch.shape[1:3]\n",
        "    height_to_pad = (align - height % align) if height % align != 0 else 0\n",
        "    width_to_pad = (align - width % align) if width % align != 0 else 0\n",
        "    crop_region = [height_to_pad >> 1, width_to_pad >> 1, height + (height_to_pad >> 1), width + (width_to_pad >> 1)]\n",
        "    batch = np.pad(batch, ((0, 0), (height_to_pad >> 1, height_to_pad - (height_to_pad >> 1)),\n",
        "                           (width_to_pad >> 1, width_to_pad - (width_to_pad >> 1)), (0, 0)), mode='constant')\n",
        "    return batch, crop_region\n",
        "\n",
        "def load_image(path, align=64):\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB).astype(np.float32) / np.float32(255)\n",
        "    image_batch, crop_region = pad_batch(np.expand_dims(image, axis=0), align)\n",
        "    return image_batch, crop_region\n",
        "\n",
        "def inference(model, img1: str, img2: str, inter_frames: int = 2):\n",
        "    img_batch_1, crop_region_1 = load_image(img1)\n",
        "    img_batch_2, crop_region_2 = load_image(img2)\n",
        "    img_batch_1 = torch.from_numpy(img_batch_1).permute(0, 3, 1, 2)\n",
        "    img_batch_2 = torch.from_numpy(img_batch_2).permute(0, 3, 1, 2)\n",
        "    results = [img_batch_1, img_batch_2]\n",
        "    idxes = [0, inter_frames + 1]\n",
        "    remains = list(range(1, inter_frames + 1))\n",
        "    splits = torch.linspace(0, 1, inter_frames + 2)\n",
        "\n",
        "    for _ in range(len(remains)):\n",
        "        starts = splits[idxes[:-1]]\n",
        "        ends = splits[idxes[1:]]\n",
        "        distances = ((splits[None, remains] - starts[:, None]) / (ends[:, None] - starts[:, None]) - .5).abs()\n",
        "        matrix = torch.argmin(distances).item()\n",
        "        start_i, step = np.unravel_index(matrix, distances.shape)\n",
        "        end_i = start_i + 1\n",
        "\n",
        "        x0 = results[start_i]\n",
        "        x1 = results[end_i]\n",
        "        x0 = x0.cuda()\n",
        "        x1 = x1.cuda()\n",
        "        dt = x0.new_full((1, 1), (splits[remains[step]] - splits[idxes[start_i]])) / (splits[idxes[end_i]] - splits[idxes[start_i]])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model(x0, x1, dt)\n",
        "        insert_position = bisect.bisect_left(idxes, remains[step])\n",
        "        idxes.insert(insert_position, remains[step])\n",
        "        results.insert(insert_position, prediction.clamp(0, 1).cpu().float())\n",
        "        del remains[step]\n",
        "\n",
        "    y1, x1, y2, x2 = crop_region_1\n",
        "    frames = [(tensor[0] * 255).byte().flip(0).permute(1, 2, 0).numpy()[y1:y2, x1:x2].copy() for tensor in results]\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8IXGxPKaGGYN"
      },
      "outputs": [],
      "source": [
        "from torch.hub import download_url_to_file\n",
        "FILM_MODEL_URL = 'https://huggingface.co/nguu/film-pytorch/resolve/main'\n",
        "FILM_MODEL = 'film_net_fp32.pt' #@param [\"film_net_fp16.pt\", \"film_net_fp32.pt\"]\n",
        "model_link = f'{FILM_MODEL_URL}/{FILM_MODEL}'\n",
        "model_path = f'{CKPT_DIR}/{FILM_MODEL}'\n",
        "if not os.path.exists(model_path):\n",
        "  download_url_to_file(model_link, model_path)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "precision = torch.float16 if FILM_MODEL == 'film_net_fp16.pt' else torch.float32\n",
        "model = torch.jit.load(model_path, map_location='cpu')\n",
        "model.eval().to(device=device, dtype=precision)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract Video Frames (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w2PAl43hwsqw"
      },
      "outputs": [],
      "source": [
        "INPUT_VIDEO = '/content/video.mp4' #@param {type:'string'}\n",
        "EXPORT_FRAME_DIR = '/content/film/temp' #@param {type:'string'}\n",
        "if os.path.exists(EXPORT_FRAME_DIR):\n",
        "  shutil.rmtree(EXPORT_FRAME_DIR)\n",
        "os.makedirs(EXPORT_FRAME_DIR, exist_ok=True)\n",
        "\n",
        "os.system(f'ffmpeg -i \"{INPUT_VIDEO}\" \"{EXPORT_FRAME_DIR}/%06d.png\"')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frame Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zwmqMnB8M4Y6"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "INTER_NUM = 2 #@param {type:'integer'}\n",
        "INPUT_FRAME_DIR = '/content/film/temp' #@param {type:'string'}\n",
        "OUTPUT_FRAME_DIR = '/content/film/output' #@param {type:'string'}\n",
        "\n",
        "sources = sorted([f'{INPUT_FRAME_DIR}/{item}' for item in os.listdir(INPUT_FRAME_DIR)])\n",
        "frames = []\n",
        "\n",
        "for index in tqdm(range(0, len(sources) - 1), f'generate frames'):\n",
        "  output = inference(model, sources[index], sources[index + 1], INTER_NUM)\n",
        "  if index == len(sources) - 1:\n",
        "    frames += output\n",
        "    break\n",
        "  else:\n",
        "    frames += output[:-1]\n",
        "\n",
        "if OUTPUT_FRAME_DIR:\n",
        "  if os.path.exists(OUTPUT_FRAME_DIR):\n",
        "    shutil.rmtree(OUTPUT_FRAME_DIR)\n",
        "  os.makedirs(OUTPUT_FRAME_DIR, exist_ok=True)\n",
        "\n",
        "  for index, frame in enumerate(frames):\n",
        "    file_path = f'{OUTPUT_FRAME_DIR}/{str(index).zfill(4)}.png'\n",
        "    cv2.imwrite(file_path, frame, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frames to video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0sYGxi8FrjRz"
      },
      "outputs": [],
      "source": [
        "FRAME_DIR = '/content/film/output' #@param {type:'string'}\n",
        "OUTPUT_VIDEO_PATH = '/content/film/result.mp4' #@param {type:'string'}\n",
        "OUTPUT_VIDEO_FPS = 24 #@param {type:'integer'}\n",
        "os.system(f'ffmpeg -y -r {OUTPUT_VIDEO_FPS} -i \"{FRAME_DIR}/%04d.png\" -c:v libx264 -crf 18 -pix_fmt yuv420p \"{OUTPUT_VIDEO_PATH}\"')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fixer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "utssHHSg06MS"
      },
      "outputs": [],
      "source": [
        "#@title Fix: A UTF-8 locale is required. Got ANSI_X3.4-1968\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
