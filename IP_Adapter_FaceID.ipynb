{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IP Adapter FaceID\n",
        "\n",
        "[![Model on HF](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-blue)](https://huggingface.co/h94/IP-Adapter-FaceID)\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nguu/maze/blob/main/IP_Adapter_FaceID.ipynb)\n",
        "[![GitHub Repository](https://img.shields.io/github/stars/tencent-ailab/IP-Adapter?style=social)](https://github.com/tencent-ailab/IP-Adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enviroment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_m2Fgy77OtyV"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "USE_DRIVE = False #@param {type:'boolean'}\n",
        "if USE_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "%pip install -q diffusers insightface onnxruntime einops accelerate\n",
        "%pip install -q git+https://github.com/tencent-ailab/IP-Adapter.git\n",
        "!wget https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sd15.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading IP Adapter Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wOxdFodtJnpj"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "from insightface.app import FaceAnalysis\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, AutoencoderKL\n",
        "from ip_adapter.ip_adapter_faceid import IPAdapterFaceID\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "device = 'cuda'\n",
        "ldm_model_path = 'AVIIAX/majic7.1' #@param {type:'string'}\n",
        "vae_model_path = 'stabilityai/sd-vae-ft-mse' #@param {type:'string'}\n",
        "ipa_model_path = 'ip-adapter-faceid_sd15.bin'\n",
        "device_providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
        "face_analyst = FaceAnalysis(name=\"buffalo_l\", providers=['CPUExecutionProvider'])\n",
        "face_analyst.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "noise_scheduler = DDIMScheduler(\n",
        "    num_train_timesteps=1000,\n",
        "    beta_start=0.00085,\n",
        "    beta_end=0.012,\n",
        "    beta_schedule=\"scaled_linear\",\n",
        "    clip_sample=False,\n",
        "    set_alpha_to_one=False,\n",
        "    steps_offset=1,\n",
        ")\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    ldm_model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    scheduler=noise_scheduler,\n",
        "    vae=AutoencoderKL.from_pretrained(\n",
        "        vae_model_path,\n",
        "        torch_dtype=torch.float16,\n",
        "    ),\n",
        "    feature_extractor=None,\n",
        "    safety_checker=None,\n",
        ")\n",
        "pipe.to(device)\n",
        "\n",
        "ip_model = IPAdapterFaceID(pipe, ipa_model_path, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Face Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ob8JBjphJYxu"
      },
      "outputs": [],
      "source": [
        "SOURCE_IMAGE = '/content/face-demo.jpg' #@param {type:'string'}\n",
        "\n",
        "src_image = cv2.imread(SOURCE_IMAGE)\n",
        "src_faces = face_analyst.get(src_image)\n",
        "\n",
        "faceids = torch.from_numpy(src_faces[0].normed_embedding).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Images with Face Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Nf-V8EAoJmL9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "PROMPT = \"high quality, masterpiece, landscape, 1girl, white dress\" #@param {type:'string'}\n",
        "NEG_PROMPT = \"monochrome, lowres, bad anatomy, worst quality, low quality, blurry, nsfw\" #@param {type:'string'}\n",
        "WIDTH = 512 #@param {type:'integer'}\n",
        "HEIGHT = 768 #@param {type:'integer'}\n",
        "BATCH_SIZE = 2 #@param {type:'integer'}\n",
        "STEPS = 30 #@param {type:'integer'}\n",
        "SEED = -1 #@param {type:'integer'}\n",
        "\n",
        "images = ip_model.generate(\n",
        "    prompt=PROMPT,\n",
        "    negative_prompt=NEG_PROMPT,\n",
        "    faceid_embeds=faceids,\n",
        "    num_samples=BATCH_SIZE,\n",
        "    width=WIDTH,\n",
        "    height=HEIGHT,\n",
        "    num_inference_steps=STEPS,\n",
        "    seed=random.randint(0, 999999999) if SEED == -1 else SEED,\n",
        ")\n",
        "\n",
        "grid = image_grid(images, 1, BATCH_SIZE)\n",
        "grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Result Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WgEAFm_wuOg1"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "OUTPUT_DIR = '/content/output' #@param {type:'string'}\n",
        "time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "for index, image in enumerate(images):\n",
        "  name = f'{time}-{index}.png'\n",
        "  image.save(f'{OUTPUT_DIR}/{name}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
